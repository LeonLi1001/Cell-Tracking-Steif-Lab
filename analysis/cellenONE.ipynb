{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This document serves as an analysis of cellenONE \n",
    "\n",
    "What we want to do is to find false predictions which incorporates: \n",
    "    1. Cells that are within the ranges but discarded \n",
    "    2. Cells that are out of the ranges but kept \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Among all the recorded how many are not allowed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_csv('/projects/steiflab/scratch/leli/A138856A/htert_20230822_131349_843.Run/record.csv')\n",
    "\n",
    "# Parameters from the image\n",
    "diameter_min = 5\n",
    "diameter_max = 50\n",
    "elongation_max = 4\n",
    "ejection_boundary = 267\n",
    "sedimentation_boundary = 200\n",
    "\n",
    "# Filter the data\n",
    "# Finding particles with diameter outside the specified range\n",
    "outside_diameter = df[(df['Diameter'] < diameter_min) | (df['Diameter'] > diameter_max)]\n",
    "\n",
    "# Finding particles with elongation greater than the specified max\n",
    "outside_elongation = df[df['Elongation'] > elongation_max]\n",
    "\n",
    "# Finding particles outside the ejection boundary\n",
    "outside_ejection_boundary = df[df['X'] > ejection_boundary]\n",
    "\n",
    "# Finding particles outside the sedimentation boundary\n",
    "outside_sedimentation_boundary = df[df['Y'] < sedimentation_boundary]\n",
    "\n",
    "# Combining all filters to find any particles outside the boundaries\n",
    "outside_all = pd.concat([outside_diameter, outside_elongation, outside_ejection_boundary, outside_sedimentation_boundary]).drop_duplicates()\n",
    "\n",
    "# Display the results\n",
    "print(\"Particles outside diameter boundaries:\")\n",
    "print(outside_diameter)\n",
    "\n",
    "print(\"\\nParticles outside elongation boundaries:\")\n",
    "print(outside_elongation)\n",
    "\n",
    "print(\"\\nParticles outside ejection boundary:\")\n",
    "print(outside_ejection_boundary)\n",
    "\n",
    "print(\"\\nParticles outside sedimentation boundary:\")\n",
    "print(outside_sedimentation_boundary)\n",
    "\n",
    "print(\"\\nParticles outside any of the specified boundaries:\")\n",
    "print(outside_all)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going back to the post processing steps \n",
    "\n",
    "We need to have a look at the frame numbers and compare with the classic normal ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Read the TXT file into a pandas DataFrame\n",
    "file_path = '/projects/steiflab/scratch/leli/trackastra/A138856A/htert_20230822_131349_843.Run/tracked_postprocessed/man_track.txt'\n",
    "df = pd.read_csv(file_path, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent']) # Adjust separator if necessary\n",
    "\n",
    "# Step 2: Calculate the number of frames for each track\n",
    "df['num_frames'] = df['End'] - df['Start'] + 1\n",
    "\n",
    "# Step 3: Generate summary statistics\n",
    "mean_frames = df['num_frames'].mean()\n",
    "median_frames = df['num_frames'].median()\n",
    "std_frames = df['num_frames'].std()\n",
    "min_frames = df['num_frames'].min()\n",
    "max_frames = df['num_frames'].max()\n",
    "\n",
    "summary_stats = {\n",
    "    'Mean': mean_frames,\n",
    "    'Median': median_frames,\n",
    "    'Standard Deviation': std_frames,\n",
    "    'Minimum': min_frames,\n",
    "    'Maximum': max_frames\n",
    "}\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "for stat, value in summary_stats.items():\n",
    "    print(f\"{stat}: {value}\")\n",
    "\n",
    "# Step 4: Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['num_frames'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Number of Frames')\n",
    "plt.xlabel('Number of Frames')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Add summary statistics to the plot\n",
    "textstr = '\\n'.join((\n",
    "    f\"Mean: {mean_frames:.2f}\",\n",
    "    f\"Median: {median_frames:.2f}\",\n",
    "    f\"Std Dev: {std_frames:.2f}\",\n",
    "    f\"Min: {min_frames}\",\n",
    "    f\"Max: {max_frames}\"\n",
    "))\n",
    "\n",
    "# Place the summary statistics text box on the plot\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "plt.gcf().text(0.95, 0.5, textstr, fontsize=12, bbox=props, transform=plt.gcf().transFigure)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Read the TXT file into a pandas DataFrame\n",
    "file_path = '/projects/steiflab/scratch/leli/trackastra/A138974A/PrintRun_Apr1223_1311/tracked_postprocessed/man_track.txt'\n",
    "df = pd.read_csv(file_path, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent']) # Adjust separator if necessary\n",
    "\n",
    "# Step 2: Calculate the number of frames for each track\n",
    "df['num_frames'] = df['End'] - df['Start'] + 1\n",
    "\n",
    "# Step 3: Generate summary statistics\n",
    "mean_frames = df['num_frames'].mean()\n",
    "median_frames = df['num_frames'].median()\n",
    "std_frames = df['num_frames'].std()\n",
    "min_frames = df['num_frames'].min()\n",
    "max_frames = df['num_frames'].max()\n",
    "\n",
    "summary_stats = {\n",
    "    'Mean': mean_frames,\n",
    "    'Median': median_frames,\n",
    "    'Standard Deviation': std_frames,\n",
    "    'Minimum': min_frames,\n",
    "    'Maximum': max_frames\n",
    "}\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "for stat, value in summary_stats.items():\n",
    "    print(f\"{stat}: {value}\")\n",
    "\n",
    "# Step 4: Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['num_frames'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Number of Frames')\n",
    "plt.xlabel('Number of Frames')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Add summary statistics to the plot\n",
    "textstr = '\\n'.join((\n",
    "    f\"Mean: {mean_frames:.2f}\",\n",
    "    f\"Median: {median_frames:.2f}\",\n",
    "    f\"Std Dev: {std_frames:.2f}\",\n",
    "    f\"Min: {min_frames}\",\n",
    "    f\"Max: {max_frames}\"\n",
    "))\n",
    "\n",
    "# Place the summary statistics text box on the plot\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "plt.gcf().text(0.95, 0.5, textstr, fontsize=12, bbox=props, transform=plt.gcf().transFigure)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix tracking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the parameters that we set up will not work for the cellenONE so we need to change all that. To reduce over correction, we set up boundries to increase accuracy when it comes to the frame numbers. The tracks need to have a certain frame number already for us to make decisions but now we need to lower it or make another strategic move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import label\n",
    "import joblib\n",
    "import tifffile as tiff\n",
    "from skimage.morphology import binary_erosion\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "def connect_objects_localized(mask1, mask2, kernel_size=5, iterations=1):\n",
    "    \"\"\"\n",
    "    Connects objects in two masks using a localized morphological dilation.\n",
    "\n",
    "    Parameters:\n",
    "    - mask1: numpy array, the first mask.\n",
    "    - mask2: numpy array, the second mask.\n",
    "    - kernel_size: int, size of the dilation kernel.\n",
    "    - iterations: int, number of dilation iterations.\n",
    "\n",
    "    Returns:\n",
    "    - connected_labels: numpy array, the labeled image after connecting objects.\n",
    "    \"\"\"\n",
    "    combined_mask = np.maximum(mask1, mask2)\n",
    "    binary_mask = (combined_mask > 0)\n",
    "    distance = distance_transform_edt(binary_mask)\n",
    "    markers, _ = label(binary_mask)\n",
    "    labels = watershed(-distance, markers, mask=binary_mask)\n",
    "    connection_mask = np.zeros_like(combined_mask)\n",
    "    for label_val in np.unique(labels):\n",
    "        if label_val == 0:\n",
    "            continue\n",
    "        component_mask = (labels == label_val)\n",
    "        if np.sum(component_mask & mask1) > 0 and np.sum(component_mask & mask2) > 0:\n",
    "            connection_mask[component_mask] = 255\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    eroded_connection = binary_erosion(connection_mask, kernel).astype(np.uint8) * 255\n",
    "    connected_objects = np.where(eroded_connection > 0, eroded_connection, combined_mask)\n",
    "    return connected_objects\n",
    "\n",
    "def get_centroid_y(mask, label_value):\n",
    "    regions = regionprops(mask)\n",
    "    for region in regions:\n",
    "        if region.label == label_value:\n",
    "            return region.centroid[1]  # Corrected to return the y-coordinate\n",
    "    return None\n",
    "\n",
    "def update_track_info_across_frame(old_track_info_df, track_info_df, frame, frame_number):\n",
    "    unique_labels = np.unique(frame)\n",
    "    unique_labels = unique_labels[unique_labels != 0]  # Remove background (label 0)\n",
    "\n",
    "    for track_id in unique_labels:\n",
    "        row = track_info_df[track_info_df['Track_ID'] == track_id]\n",
    "\n",
    "        if not row.empty:\n",
    "            start_frame = int(row['Start'].values[0])\n",
    "            end_frame = int(row['End'].values[0])\n",
    "            start_frame = min(start_frame, frame_number)\n",
    "            end_frame = max(end_frame, frame_number)\n",
    "            track_info_df.loc[track_info_df['Track_ID'] == track_id, 'Start'] = start_frame\n",
    "            track_info_df.loc[track_info_df['Track_ID'] == track_id, 'End'] = end_frame\n",
    "        else:\n",
    "            parent_value = old_track_info_df.loc[old_track_info_df['Track_ID'] == track_id, 'Parent'].values[0] if track_id in old_track_info_df['Track_ID'].values else 0\n",
    "            new_row = pd.DataFrame({\n",
    "                'Track_ID': [track_id],\n",
    "                'Start': [frame_number],\n",
    "                'End': [frame_number],\n",
    "                'Parent': [parent_value]\n",
    "            })\n",
    "            track_info_df = pd.concat([track_info_df, new_row], ignore_index=True)\n",
    "    \n",
    "    return track_info_df\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def color_labels(tif, labels, colors):\n",
    "    \"\"\"\n",
    "    Color the specified labels in the TIFF image with the given colors.\n",
    "\n",
    "    Parameters:\n",
    "    - tif: numpy array, the TIFF image.\n",
    "    - labels: list of int, the labels to color.\n",
    "    - colors: list of tuple, the colors corresponding to each label.\n",
    "\n",
    "    Returns:\n",
    "    - colored_img: numpy array, the image with colored labels.\n",
    "    \"\"\"\n",
    "    colored_img = cv2.cvtColor(tif.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for label, color in zip(labels, colors):\n",
    "        mask = (tif == label)\n",
    "        colored_img[mask] = color\n",
    "\n",
    "    return colored_img\n",
    "\n",
    "def display_colored_images(frame, labels_to_color, title):\n",
    "    \"\"\"\n",
    "    Display the colored images for the specified labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = [\n",
    "        (255, 0, 0),  # Red\n",
    "        (0, 255, 0),  # Green\n",
    "        (0, 0, 255),  # Blue\n",
    "        (255, 255, 0),  # Yellow\n",
    "        (255, 0, 255), # Magenta\n",
    "        (255, 165, 0),  # Orange\n",
    "        (128, 0, 128) ,  # Purple\n",
    "    ]\n",
    "\n",
    "    colored_img1 = color_labels(frame, labels_to_color, colors)\n",
    "\n",
    "    plt.imshow(colored_img1)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def postprocess_frame(frame, track_info, classification, min_size=100):\n",
    "    \n",
    "    groups = track_info.groupby('Root')['Track_ID'].apply(list).to_dict()\n",
    "    unique_labels = np.unique(frame)\n",
    "    unique_labels = unique_labels[unique_labels != 0]\n",
    "\n",
    "    groups = {root: tracks for root, tracks in groups.items() if any(track in unique_labels for track in tracks)}\n",
    "\n",
    "    for root, group in groups.items():\n",
    "        print(f\"This group has root {root} and contains {group}\")\n",
    "\n",
    "        objs_to_be_merged = []\n",
    "\n",
    "        for track_id in group:\n",
    "            print(f\"iteration: {track_id} where it is \\n {track_info.loc[track_info['Track_ID'] == track_id]}\")\n",
    "            if track_id == root or track_info.loc[track_info['Track_ID'] == track_id, 'Parent'].values[0] == 0:\n",
    "                continue\n",
    "            print(f\"iteration: {track_id}\")\n",
    "            mask = (frame == track_id)\n",
    "            print(f\"This objects {track_id} has a size of {np.sum(mask)}\")\n",
    "\n",
    "            # Remove small objects\n",
    "            if np.sum(mask) < min_size:\n",
    "                frame[mask] = 0\n",
    "                print(\"Object with track id: {track_id} is too small so we remove all together\")\n",
    "                continue\n",
    "\n",
    "            action = classification.loc[track_id, 'action']\n",
    "\n",
    "            if action == 1:\n",
    "                print(f\"Object with track id: {track_id} has action 1\")\n",
    "                continue  # Keep as is\n",
    "\n",
    "            elif action == 2:\n",
    "                print(f\"Object with track id: {track_id} has action 2\")\n",
    "                frame[mask] = 0  # Remove\n",
    "\n",
    "            elif action == 0:\n",
    "                print(f\"Object with track id: {track_id} has action 0\")\n",
    "                centroid_y = get_centroid_y(frame, track_id)\n",
    "                objs_to_be_merged.append((track_id, centroid_y))\n",
    "        \n",
    "        if len(objs_to_be_merged) != 0:\n",
    "            objs_to_be_merged.sort(key=lambda x: x[1])\n",
    "            print(f\"These are the objects that will be merged {objs_to_be_merged}\")\n",
    "\n",
    "            combined_mask = (frame == objs_to_be_merged[0][0])\n",
    "            for i in range(1, len(objs_to_be_merged)):\n",
    "                        next_mask = (frame == objs_to_be_merged[i][0])\n",
    "\n",
    "                        # here this is becuase we realize that the function morphologyEx alter other part of the masks so it does not just add the connecting part it alters the original\n",
    "                        old_mask1 = combined_mask.copy()\n",
    "                        old_mask2 = next_mask.copy()\n",
    "\n",
    "                        for kernel_size in range(4):\n",
    "                            temp = np.logical_or(combined_mask, next_mask).astype(np.uint8)\n",
    "                            combined_mask = cv2.morphologyEx(temp, cv2.MORPH_CLOSE, np.ones((kernel_size * 5, kernel_size * 5), np.uint8))\n",
    "                            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(combined_mask, connectivity=8)\n",
    "                            if num_labels-1 == 1: \n",
    "                                break\n",
    "                        \n",
    "                        combined_mask = np.logical_or(combined_mask, old_mask1).astype(np.uint8)\n",
    "                        combined_mask = np.logical_or(combined_mask, old_mask2).astype(np.uint8)\n",
    "                        \n",
    "                        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(combined_mask, connectivity=8)\n",
    "                        if num_labels-1 > 1:\n",
    "                            #display_colored_images(combined_mask, labels_to_color = [1, 2, 3, 4], title= f'current Frame: {frame_num}')\n",
    "                            print(\"Failed to connect objects after multiple attempts.\")\n",
    "                        else: \n",
    "                            print(f\"Succeeded to connect objects with kernel size {kernel_size}\")\n",
    "\n",
    "            # do the final painting of pixels \n",
    "            frame[combined_mask > 0] = root\n",
    "\n",
    "    return frame\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def predict_next_centroids(centroids, centroids_frame_with_prediction, predict_this_frame):\n",
    "    \"\"\"\n",
    "    Predicts the next centroid positions given a list of centroids and the corresponding frame numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - centroids: list of tuples (y, x) representing the coordinates of the centroids.\n",
    "    - centroids_frame_with_prediction: list of frame numbers corresponding to the centroids.\n",
    "\n",
    "    Returns:\n",
    "    - predicted_centroids: tuple (y, x) representing the predicted coordinates of the next centroid.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame for easy handling\n",
    "    df = pd.DataFrame(centroids, columns=['y', 'x'])\n",
    "    df['frame'] = centroids_frame_with_prediction\n",
    "\n",
    "    # Extract features and targets\n",
    "    X = df['frame'].values.reshape(-1, 1)  # Frames as features\n",
    "    y_y = df['y'].values  # y-coordinates as target\n",
    "    y_x = df['x'].values  # x-coordinates as target\n",
    "\n",
    "    # Fit linear regression models\n",
    "    model_y = LinearRegression()\n",
    "    model_x = LinearRegression()\n",
    "    model_y.fit(X, y_y)\n",
    "    model_x.fit(X, y_x)\n",
    "\n",
    "    # Predict the next frame\n",
    "    next_frame = np.array([predict_this_frame]).reshape(-1, 1)\n",
    "    pred_y = model_y.predict(next_frame)[0]\n",
    "    pred_x = model_x.predict(next_frame)[0]\n",
    "\n",
    "    return pred_y, pred_x\n",
    "\n",
    "def remove_track(track_info_file, target_tif_dir, to_be_removed_id):\n",
    "\n",
    "    track_info = pd.read_csv(track_info_file, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent'])\n",
    "    track_id, start_frame, end_frame, parent_id = track_info.loc[track_info['Track_ID'] == to_be_removed_id].values[0]\n",
    "\n",
    "    for frame_number in range(start_frame, end_frame + 1):\n",
    "        frame_path = os.path.join(target_tif_dir, f'man_track{frame_number:04d}.tif')\n",
    "        if os.path.exists(frame_path):\n",
    "            frame = tiff.imread(frame_path)\n",
    "            frame[frame == to_be_removed_id] = 0\n",
    "            tiff.imwrite(frame_path, frame)\n",
    "            print(f\"Removed track {to_be_removed_id} from frame {frame_number}\")\n",
    "\n",
    "    new_track_info = track_info[track_info['Track_ID'] != to_be_removed_id]\n",
    "    new_track_info.to_csv(track_info_file, sep=' ', index=False, header=False)\n",
    "    \n",
    "    return new_track_info\n",
    "\n",
    "def diverge_track(track_info_file, target_tif_dir, to_be_split_id, new_id, diverging_start_frame):\n",
    "\n",
    "    track_info = pd.read_csv(track_info_file, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent'])\n",
    "    track_id, start_frame, end_frame, parent_id = track_info.loc[track_info['Track_ID'] == to_be_split_id].values[0]\n",
    "\n",
    "    if diverging_start_frame <= start_frame or diverging_start_frame > end_frame:\n",
    "        raise ValueError(\"Diverging start frame must be within the original track's range.\")\n",
    "    \n",
    "    # Iterate through the frames and update the track\n",
    "    for frame_number in range(diverging_start_frame, end_frame + 1):\n",
    "        frame_path = os.path.join(target_tif_dir, f'man_track{frame_number:04d}.tif')\n",
    "        if os.path.exists(frame_path):\n",
    "            frame = tiff.imread(frame_path)\n",
    "            frame[frame == to_be_split_id] = new_id\n",
    "            tiff.imwrite(frame_path, frame)\n",
    "            print(f\"Diverge frame {frame_number}: track {to_be_split_id} -> {new_id}\")\n",
    "    \n",
    "    # Create a new row for the new track\n",
    "    new_track_row = pd.DataFrame({\n",
    "        'Track_ID': [new_id],\n",
    "        'Start': [diverging_start_frame],\n",
    "        'End': [end_frame],\n",
    "        'Parent': [to_be_split_id]\n",
    "    })\n",
    "    \n",
    "    # Append the new track row to the DataFrame \n",
    "    new_track_info = track_info._append(new_track_row, ignore_index=True)\n",
    "    temp = new_track_info['Track_ID'].values\n",
    "    print(f\"Added {new_id} in the track info so now {new_id} is in new_track_info {new_id in temp}\")\n",
    "\n",
    "    # Update the end frame of the original track\n",
    "    new_track_info.loc[new_track_info['Track_ID'] == to_be_split_id, 'End'] = diverging_start_frame - 1\n",
    "\n",
    "    new_track_info.to_csv(track_info_file, sep=' ', index=False, header=False)\n",
    "\n",
    "    return new_track_info\n",
    "\n",
    "def merge_track(track_info_file, target_tif_dir, to_be_merged_ids):\n",
    "\n",
    "    track_info = pd.read_csv(track_info_file, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent'])\n",
    "    new_track_info = track_info.copy()\n",
    "\n",
    "    # Determine alpha and beta tracks based on start frames\n",
    "    alpha_id, beta_id = to_be_merged_ids if track_info.loc[track_info['Track_ID'] == to_be_merged_ids[0], 'Start'].values[0] < track_info.loc[track_info['Track_ID'] == to_be_merged_ids[1], 'Start'].values[0] else to_be_merged_ids[::-1]\n",
    "\n",
    "    alpha_id, alpha_start_frame, alpha_end_frame, alpha_parent_id = track_info.loc[track_info['Track_ID'] == alpha_id].values[0]\n",
    "    beta_id, beta_start_frame, beta_end_frame, beta_parent_id = track_info.loc[track_info['Track_ID'] == beta_id].values[0]\n",
    "\n",
    "    # For frames from alpha_end_frame + 1 to beta_end_frame, all beta track objects are relabeled to alpha.\n",
    "    sizes_after_alpha_end = []\n",
    "    for frame_number in range(alpha_end_frame+1, beta_end_frame+1):\n",
    "        frame_path = os.path.join(target_tif_dir, f'man_track{frame_number:04d}.tif')\n",
    "        if os.path.exists(frame_path):\n",
    "            frame = tiff.imread(frame_path)\n",
    "            beta_mask = (frame == beta_id).astype(np.uint8)\n",
    "            sizes_after_alpha_end.append(np.sum(beta_mask))\n",
    "            frame[beta_mask > 0] = alpha_id  # Relabel beta to alpha\n",
    "            tiff.imwrite(frame_path, frame)\n",
    "            print(f\"Merge frame {frame_number}: track {beta_id} -> {alpha_id}\")\n",
    "\n",
    "    median = np.median(sizes_after_alpha_end)\n",
    "    mad = np.median(np.abs(sizes_after_alpha_end - median)) \n",
    "    lower_bound = median - 2 * mad\n",
    "\n",
    "    # assume the beta starts at the same frame but ends at (include) alpha_end_frame\n",
    "    new_beta_start_frame = beta_start_frame.copy()\n",
    "    new_beta_end_frame = alpha_end_frame.copy()\n",
    "\n",
    "    if beta_start_frame < alpha_end_frame+1:\n",
    "\n",
    "        for frame_number in range(beta_start_frame, alpha_end_frame + 1):\n",
    "            frame_path = os.path.join(target_tif_dir, f'man_track{frame_number:04d}.tif')\n",
    "            if os.path.exists(frame_path):\n",
    "                frame = tiff.imread(frame_path)\n",
    "                beta_mask = (frame == beta_id).astype(np.uint8)\n",
    "                size_beta = np.sum(beta_mask)\n",
    "                if size_beta < lower_bound:\n",
    "                    frame[beta_mask > 0] = 0  # Remove small objects\n",
    "                    print(f\"Removed small object in frame {frame_number} with size {size_beta}\")\n",
    "                else:\n",
    "                    frame[beta_mask > 0] = alpha_id  # Merge beta into alpha\n",
    "                    print(f\"Merged frame {frame_number}: track {beta_id} -> {alpha_id} (This is before alpha end frame)\")\n",
    "                new_beta_start_frame = frame_number + 1\n",
    "                tiff.imwrite(frame_path, frame)\n",
    "\n",
    "    # Update track_info DataFrame\n",
    "    new_track_info.loc[new_track_info['Track_ID'] == alpha_id, 'End'] = max(alpha_end_frame, beta_end_frame)\n",
    "    if new_beta_start_frame > new_beta_end_frame: \n",
    "        print(f\"Remove track ID: {beta_id}\")\n",
    "        new_track_info = new_track_info[new_track_info['Track_ID'] != beta_id]\n",
    "\n",
    "    else:\n",
    "        print(f\"Putting in new start and end frames {new_beta_start_frame}, {new_beta_end_frame}\")\n",
    "        new_track_info.loc[new_track_info['Track_ID'] == beta_id, 'Start'] = new_beta_start_frame\n",
    "        new_track_info.loc[new_track_info['Track_ID'] == beta_id, 'End'] = new_beta_end_frame\n",
    "\n",
    "    new_track_info.to_csv(track_info_file, sep=' ', index=False, header=False)\n",
    "\n",
    "    temp = new_track_info[\"Track_ID\"].values\n",
    "    print(f\"confirmation that the new track info file do not have beta id {beta_id} {beta_id not in temp}\")\n",
    "\n",
    "    return new_track_info\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def maj_object_within_radius(frame, point, radius):\n",
    "    \"\"\"\n",
    "    Check if there are any object pixels within a radius around a specified point\n",
    "    and return the label of the object with the most pixels inside the radius.\n",
    "\n",
    "    Parameters:\n",
    "    - frame: numpy array, the pixel assignment matrix.\n",
    "    - point: tuple (x, y), the coordinates of the given point.\n",
    "    - radius: float, the radius within which to check for object pixels.\n",
    "\n",
    "    Returns:\n",
    "    - int, label of the object with the most pixels within the radius, or 0 if none.\n",
    "    \"\"\"\n",
    "    # Get the coordinates and labels of all non-background pixels\n",
    "    object_coords = np.column_stack(np.where(frame != 0))\n",
    "    object_labels = frame[frame != 0]\n",
    "\n",
    "    # Calculate the Euclidean distance from the given point to each object pixel\n",
    "    distances = cdist([point], object_coords, metric='euclidean')\n",
    "\n",
    "    # Get pixels within the specified radius\n",
    "    within_radius = distances[0] <= radius\n",
    "    if np.any(within_radius):\n",
    "        # Count the number of pixels for each label within the radius\n",
    "        labels_within_radius = object_labels[within_radius]\n",
    "        unique_labels, counts = np.unique(labels_within_radius, return_counts=True)\n",
    "        non_zero_labels = unique_labels[unique_labels != 0]\n",
    "        if len(non_zero_labels) > 0:\n",
    "            max_count_label = non_zero_labels[np.argmax(counts[unique_labels != 0])]\n",
    "            return max_count_label\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "out_folder = \"A138856A/htert_20230822_131349_843.Run/tracked\"\n",
    "source_tif_dir = f\"/projects/steiflab/scratch/leli/trackastra/{out_folder}_postprocessed\"\n",
    "target_tif_dir = f\"/projects/steiflab/scratch/leli/trackastra/{out_folder}_postprocessed_2.0\"\n",
    "track_info_file = f'/projects/steiflab/scratch/leli/trackastra/{out_folder}_postprocessed_2.0/man_track.txt'\n",
    "\n",
    "\n",
    "os.makedirs(target_tif_dir, exist_ok=True)\n",
    "# Copy original tif files to the target directory\n",
    "if os.path.exists(target_tif_dir):\n",
    "    shutil.rmtree(target_tif_dir)\n",
    "shutil.copytree(source_tif_dir, target_tif_dir)\n",
    "\n",
    "print(\"Initiate Main track Processing ... \")\n",
    "track_info = pd.read_csv(track_info_file, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent']) # read in again the new versin of track info \n",
    "track_ids = sorted(track_info['Track_ID'])\n",
    "#track_ids  = [50]\n",
    "\n",
    "# This number is the original max track id, for divered track we would want to creat new ones\n",
    "new_track_label = np.max(track_info['Track_ID'].values)\n",
    "\n",
    "while track_ids: \n",
    "    \n",
    "    print(f\"Check for track ID: {track_ids[0]}\")\n",
    "\n",
    "    # there may be changes evertime we go throuh a track\n",
    "    track_info = pd.read_csv(track_info_file, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent']) # read in again the new versin of track info \n",
    "\n",
    "    #### Check 1: <=2 Frames\n",
    "    track_id, start_frame, end_frame, parent_id = track_info.loc[track_info['Track_ID'] == track_ids[0]].values[0]\n",
    "    if end_frame - start_frame <=0: \n",
    "        remove_track(track_info_file, target_tif_dir, to_be_removed_id = track_ids[0])\n",
    "        track_ids = track_ids[1:]\n",
    "        continue\n",
    "\n",
    "    #### Check 2: Moving up Tracks and paused tracks \n",
    "    track_id, start_frame, end_frame, parent_id = track_info.loc[track_info['Track_ID'] == track_ids[0]].values[0]\n",
    "    centroids = []\n",
    "    centroids_frame = []\n",
    "    skipped_frames = []\n",
    "    for frame_number in range(start_frame, end_frame+1):\n",
    "\n",
    "        #print(f\"centroids_with_prediction is : {centroids_with_prediction}\")\n",
    "\n",
    "        frame_path = os.path.join(target_tif_dir, f'man_track{frame_number:04d}.tif')\n",
    "        frame = tiff.imread(frame_path)\n",
    "        binary_mask = (frame == track_id).astype(np.uint8)\n",
    "\n",
    "        #When this track does not exist in this frame we keep going \n",
    "        if len(np.unique(binary_mask)) == 1:\n",
    "            skipped_frames.append(frame_number)\n",
    "            continue\n",
    "\n",
    "        # add in the centroid\n",
    "        centroid = regionprops(binary_mask)[0].centroid\n",
    "        if centroid is None: raise ValueError(\"The centroid point being added is Nnne\")\n",
    "\n",
    "        if len(centroids) >=3: # if we are in the middle of the tracklet \n",
    "            y_changes = np.diff([c[0] for c in centroids])\n",
    "            median_change = np.median(y_changes)\n",
    "            mad = np.median(np.abs(y_changes - median_change))\n",
    "            threshold = 2.5 * mad # 2.5 is the usual value but can be changed\n",
    "\n",
    "            #print(f\"The centroids are currently {centroids}\")\n",
    "\n",
    "            # here we already have the MAD threshold, the lower bound is median change in y direction - the threshold. \n",
    "            # Since the object is always going down, the y value should only increase. So once the object move up, the change in y value should be negative so it is on the lower bound. \n",
    "            # Here we are checking if it is outside the lower bound. \n",
    "            #print(f\"The difference between the current object and the last one is {np.diff([centroids[-1][0], centroid[0]])} with the last item being {centroids[-1][0]} and the current centroid y value is {centroid[0]} with the lower bound be {median_change - threshold}\")\n",
    "            if np.diff([centroids[-1][0], centroid[0]]) <= median_change - threshold: \n",
    "\n",
    "                # since this is case 2 so we add a prefix to the track id so we can come back to it\n",
    "                new_track_label = new_track_label+1\n",
    "                diverge_track(track_info_file, target_tif_dir, to_be_split_id = track_id, new_id = int(new_track_label), diverging_start_frame = frame_number)\n",
    "                track_ids.append(int(new_track_label))\n",
    "                break\n",
    "\n",
    "            elif len(skipped_frames) >=2:\n",
    "\n",
    "                # since this is case 2.5 so we add a prefix to the track id so we can come back to it\n",
    "                new_track_label = new_track_label+1\n",
    "                diverge_track(track_info_file, target_tif_dir, to_be_split_id = track_id, new_id = int(new_track_label), diverging_start_frame = frame_number)\n",
    "                track_ids.append(int(new_track_label))\n",
    "                break\n",
    "        \n",
    "        centroids.append(centroid)\n",
    "        centroids_frame.append(frame_number)\n",
    "\n",
    "\n",
    "        # else: # if we are at the beginning we do not do anything yet, might change later\n",
    "\n",
    "    #### Check 3: label switching\n",
    "    centroids_with_prediction = centroids.copy() # here this centroid will contain the LR predicted centroid\n",
    "    centroids_frame_with_prediction = centroids_frame.copy()\n",
    "\n",
    "    #print(f\"IN CASE 3: The centroids are {centroids_with_prediction} and the frame numbers are {centroids_frame_with_prediction}\")\n",
    "\n",
    "    if len(centroids_with_prediction) >= 3: \n",
    "        covered_by = []\n",
    "        \n",
    "        for frame_number in range(sorted(centroids_frame_with_prediction, reverse = True)[0] + 1, sorted(centroids_frame_with_prediction, reverse = True)[0] + 4):\n",
    "            frame_path = os.path.join(target_tif_dir, f'man_track{frame_number:04d}.tif')\n",
    "            if os.path.exists(frame_path):\n",
    "                frame = np.array(tiff.imread(frame_path))\n",
    "\n",
    "                curr_c = predict_next_centroids(centroids_with_prediction, centroids_frame_with_prediction, predict_this_frame = frame_number)\n",
    "\n",
    "                #centroids_with_prediction.append(curr_c)\n",
    "                #centroids_frame_with_prediction.append(frame_number)\n",
    "\n",
    "                if 0 <= int(curr_c[0]) < frame.shape[0] and 0 <= int(curr_c[1]) < frame.shape[1]:\n",
    "                    maj_label = maj_object_within_radius(frame, curr_c, radius = 3.5)\n",
    "                    covered_by.append(maj_label)\n",
    "                    if maj_label != 0:\n",
    "                        binary_mask = (frame == maj_label).astype(np.uint8)\n",
    "                        centroid = regionprops(binary_mask)[0].centroid\n",
    "                        centroids_with_prediction.append(curr_c)\n",
    "                        centroids_frame_with_prediction.append(frame_number)\n",
    "\n",
    "                else:\n",
    "                    print(\"prediction went out of bound\")\n",
    "                    covered_by.append(0)\n",
    "                    centroid = regionprops(binary_mask)[0].centroid\n",
    "\n",
    "\n",
    "        #print(f\"here we see that the track is covered by {covered_by} when the centroids are {centroids_with_prediction}\")\n",
    "        if len(covered_by) == 2:\n",
    "            non_zero_values = [x for x in covered_by if x > 0]\n",
    "            for label in set(non_zero_values):\n",
    "                if non_zero_values.count(label) >= 2:\n",
    "                    # the ids that are to be merge do not matter because we pick which one is which within the merge track function\n",
    "                    new = merge_track(track_info_file, target_tif_dir, to_be_merged_ids = (label, track_id))\n",
    "\n",
    "                    temp = new[\"Track_ID\"].values\n",
    "                    print(f\"The label {label} is not in the track info {label not in temp} and the track id {track_id}\")\n",
    "                    if label not in new[\"Track_ID\"].values and label in track_ids: # make sure to have .values, apparently pd series check index not the value if we do no include this :(\n",
    "                        track_ids.remove(label)\n",
    "\n",
    "    #### Check 4: Overall y movement to remove the ones that did not make a movement \n",
    "    if len(centroids) < 5 and len(centroids) > 1:\n",
    "        overall_y_movement = centroids[-1][0] - centroids[0][0]\n",
    "        if overall_y_movement <= 5:\n",
    "            remove_track(track_info_file, target_tif_dir, to_be_removed_id = track_ids[0])\n",
    "\n",
    "\n",
    "    assert len(track_ids) == len(np.unique(track_ids))\n",
    "\n",
    "    track_ids = track_ids[1:]\n",
    "\n",
    "\n",
    "print(\"Main track Processing completed.\")\n",
    "\n",
    "print(\"initiate updating tracking info csv at the very end to correct and ensure the track info final version\")\n",
    "\n",
    "track_info = pd.read_csv(track_info_file, sep='\\s+', names=['Track_ID', 'Start', 'End', 'Parent']) # read in again the new versin of track info \n",
    "new_track_info = pd.DataFrame(columns=track_info.columns)\n",
    "for filename in os.listdir(target_tif_dir):\n",
    "    if not filename.startswith(\"._\") and filename.endswith(\".tif\"):\n",
    "        frame_path = os.path.join(target_tif_dir, filename)\n",
    "        frame = tiff.imread(frame_path)\n",
    "\n",
    "        frame_num = int(filename.replace('man_track', '').replace('.tif', ''))\n",
    "        new_track_info = update_track_info_across_frame(track_info, new_track_info, frame, frame_num)\n",
    "        new_track_info.to_csv(os.path.join(target_tif_dir, \"man_track.txt\"), sep=' ', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from skimage.segmentation import watershed\n",
    "from scipy.ndimage import distance_transform_edt, center_of_mass\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.spatial.distance import cdist\n",
    "from PIL import Image\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def numerical_sort(value):\n",
    "    \"\"\"\n",
    "    Extracts the numeric part from the filename for sorting.\n",
    "    Assumes that the filename format is '<number>_htert_Run'.\n",
    "    \"\"\"\n",
    "    parts = re.findall(r'\\d+', value)\n",
    "    return int(parts[0]) if parts else value\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    filenames = sorted([filename for filename in os.listdir(directory) if filename.endswith(\"_htert_Run.png\") and not filename.startswith(\"._\") and \"Printed\" not in filename], key = numerical_sort) # for cellenONE\n",
    "    #filenames = sorted([filename for filename in os.listdir(directory) if filename.endswith(\".png\") and not filename.startswith(\"._\")], key = numerical_sort)\n",
    "    print(f\"filenames are {filenames}\")\n",
    "\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        #img = expand_image(img, mode = \"images\")\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.rot90(img_array)\n",
    "        images.append(img_array) # for cellenONE\n",
    "    return np.array(images), [f.replace(\".png\", \"\") for f in filenames]\n",
    "\n",
    "\n",
    "def expand_image(img, mode, factor=3,):\n",
    "    # Get original dimensions\n",
    "    original_width, original_height = img.size\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = original_width * factor\n",
    "    new_height = original_height * factor\n",
    "\n",
    "    # Resize the image\n",
    "    if mode == \"images\": \n",
    "        new_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "    elif mode == \"masks\":\n",
    "        new_img = img.resize((new_width, new_height), Image.Resampling.NEAREST)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def remove_empty_frame(imgs, masks):\n",
    "    ind_to_remove = []\n",
    "    for i in range(masks.shape[0]):\n",
    "        if np.all(masks[i] == 0):\n",
    "            ind_to_remove.append(i)\n",
    "\n",
    "    imgs_new = np.delete(imgs, ind_to_remove, axis = 0)\n",
    "    masks_new = np.delete(masks, ind_to_remove, axis = 0)\n",
    "\n",
    "    assert imgs_new.shape == masks_new.shape\n",
    "\n",
    "    return imgs_new, masks_new, ind_to_remove\n",
    "\n",
    "\n",
    "def mask_to_bbox(mask):\n",
    "    \"\"\"\n",
    "    Converts a binary mask to a bounding box.\n",
    "\n",
    "    :param numpy.ndarray mask: Binary mask.\n",
    "    :return: Bounding box in the format (x, y, w, h).\n",
    "    :rtype: list[int]\n",
    "    \"\"\"\n",
    "    rows, cols = np.where(mask == 255)\n",
    "    x1, x2 = np.min(cols), np.max(cols)\n",
    "    y1, y2 = np.min(rows), np.max(rows)\n",
    "    return [x1, y1, x2-x1, y2-y1]\n",
    "\n",
    "\n",
    "def load_masks_from_directory(directory, img_shape, fix_overlap=False, overlap_threshold = 0.6, top_threshold = 0.005, bottom_threshold = 0.995):\n",
    "    \"\"\"\n",
    "    Load masks from a directory and handle overlaps if specified.\n",
    "\n",
    "    Parameters:\n",
    "    - directory: str, path to the directory containing the masks.\n",
    "    - img_shape: tuple, shape of the images.\n",
    "    - fix_overlap: bool, whether to fix overlaps between masks.\n",
    "\n",
    "    Returns:\n",
    "    - masks: numpy array, combined masks for each frame.\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    current_object_index = 1\n",
    "    frames = sorted([frame for frame in os.listdir(directory) if os.path.isdir(os.path.join(directory, frame)) and frame.endswith(\"_htert_Run\")], key = numerical_sort) # for cellenONE\n",
    "    #frames = sorted([frame for frame in os.listdir(directory) if os.path.isdir(os.path.join(directory, frame)) and frame.startswith(\"Image_\")], key = numerical_sort)\n",
    "    print(f\"The frames are {frames}\")\n",
    "\n",
    "    for frame in frames: #sorted(os.listdir(directory), key = numerical_sort):  # Loop through the frame folders\n",
    "        frame_dir = os.path.join(directory, frame)\n",
    "        #if os.path.isdir(frame_dir) and frame.startswith(\"Image_\"):  # The directory needs to start with Image for normal runs \n",
    "        if os.path.isdir(frame_dir) and frame.endswith(\"_htert_Run\"): # for cellenONE\n",
    "            frame_mask = np.zeros(img_shape, dtype=np.int32)\n",
    "\n",
    "            if fix_overlap:\n",
    "                curr_masks = []\n",
    "                \n",
    "                for filename in sorted(os.listdir(frame_dir)):\n",
    "                    if filename.endswith(\".png\") and not filename.startswith(\"._\"):  # Loop through the png files \n",
    "                        mask_path = os.path.join(frame_dir, filename)\n",
    "                        mask = Image.open(mask_path).convert('L')\n",
    "                        mask_array = np.array(mask)\n",
    "                        bbox = mask_to_bbox(mask_array)\n",
    "                        _, y, _, h = bbox\n",
    "\n",
    "                        if y >= top_threshold * mask_array.shape[0] and (y + h) <= bottom_threshold * mask_array.shape[0]:  # Ignore detections close to top and bottom thresholds\n",
    "                            if len(np.unique(mask_array)) != 2:\n",
    "                                raise ValueError(\"something is up\", np.unique(mask_array))\n",
    "                            curr_masks.append(mask_array)\n",
    "                        #else:\n",
    "                            #print(f\"Mask {filename} ignored due to top/bottom threshold\")\n",
    "\n",
    "\n",
    "                #print(f\"Number of masks in the current frame: {len(curr_masks)}\")\n",
    "\n",
    "                # Create an overlap matrix\n",
    "                overlap_matrix = np.zeros((len(curr_masks), len(curr_masks)), dtype=int)\n",
    "                for i in range(len(curr_masks)):\n",
    "                    for j in range(i + 1, len(curr_masks)):\n",
    "                        mask_i = curr_masks[i]\n",
    "                        mask_j = curr_masks[j]\n",
    "\n",
    "                        # Ensure masks are binary\n",
    "                        mask1_binary = (mask_i == 255)\n",
    "                        mask2_binary = (mask_j == 255)\n",
    "\n",
    "                        # Calculate the size of each mask\n",
    "                        size1 = np.sum(mask1_binary)\n",
    "                        size2 = np.sum(mask2_binary)\n",
    "\n",
    "                        # Identify the smaller and larger masks\n",
    "                        if size1 < size2:\n",
    "                            smaller_mask = mask1_binary\n",
    "                            larger_mask = mask2_binary\n",
    "                            smaller_size = size1\n",
    "                        else:\n",
    "                            smaller_mask = mask2_binary\n",
    "                            larger_mask = mask1_binary\n",
    "                            smaller_size = size2\n",
    "\n",
    "                        # Calculate the overlap\n",
    "                        overlap = np.sum(smaller_mask & larger_mask)\n",
    "                        overlap_percentage = overlap / smaller_size\n",
    "                        #print(f\"overalp between mask {i} and maks {j} is {overlap_percentage} with threshold being {overlap_threshold}\")\n",
    "\n",
    "                        if overlap_percentage >= overlap_threshold:\n",
    "                            overlap_matrix[i, j] = 1\n",
    "                            overlap_matrix[j, i] = 1\n",
    "\n",
    "                #print(f\"Overlap matrix:\\n{overlap_matrix}\")\n",
    "\n",
    "                # Cluster overlapping objects\n",
    "                sparse_matrix = csr_matrix(overlap_matrix)\n",
    "                n_components, labels = connected_components(csgraph=sparse_matrix, directed=False, return_labels=True)\n",
    "\n",
    "                # Group masks by their component labels to form clusters\n",
    "                clusters = [[] for _ in range(n_components)]\n",
    "                for mask_index, component_label in enumerate(labels):\n",
    "                    clusters[component_label].append(mask_index)\n",
    "\n",
    "                #print(f\"Clusters: {clusters}\")\n",
    "\n",
    "                for c in range(len(clusters)):  # Loop through each cluster and merge them\n",
    "                    masks_in_cluster = [curr_masks[j] for j in clusters[c]]\n",
    "\n",
    "                    # Create a combined mask\n",
    "                    combined_mask = np.zeros_like(masks_in_cluster[0], dtype=np.int32)\n",
    "                    for mask in masks_in_cluster:\n",
    "                        combined_mask[mask > 0] = 1\n",
    "\n",
    "                    # Label the combined mask\n",
    "                    frame_mask[combined_mask > 0] = current_object_index\n",
    "                    current_object_index += 1\n",
    "\n",
    "                    #print(f\"Processed cluster {c} with {len(masks_in_cluster)} masks.\")\n",
    "\n",
    "            else:  # If not fixing overlaps\n",
    "                for filename in sorted(os.listdir(frame_dir)):\n",
    "                    if filename.endswith(\".png\") and not filename.startswith(\"._\"):  # Loop through the png files  _htert_Run\n",
    "                        mask_path = os.path.join(frame_dir, filename)\n",
    "                        mask = Image.open(mask_path).convert('L')\n",
    "                        mask_array = np.array(mask)\n",
    "                        if len(np.unique(mask_array)) != 2:\n",
    "                            raise ValueError(\"something is up\", np.unique(mask_array))\n",
    "                        # Assign the current object index to the mask pixels\n",
    "                        frame_mask[(mask_array == 255)] = current_object_index\n",
    "                        current_object_index += 1\n",
    "                        #print(f\"Processed mask {filename} with index {current_object_index - 1}\")\n",
    "\n",
    "            masks.append(frame_mask)\n",
    "            # if np.all(frame_mask == 0): print(f\"The frame that has all zero is {frame}\")\n",
    "            #print(f\"Added frame mask for {frame}, current number of masks: {len(masks)}\")\n",
    "\n",
    "    #print(f\"Total frames processed: {len(masks)}\")\n",
    "    return np.array(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main directory\n",
    "chip = \"A138856A\" # \"A118880\" #\"A138974A\" # \"A138856A\"   A138856A/htert_20230822_131349_843.Run/tracked\n",
    "run = \"htert_20230822_131349_843.Run\" # \"PrintRun_Jan2624_1252\" # \"PrintRun_Apr1223_1311\" #'htert_20230822_131349_843.Run'\n",
    "#main_img_directory = f\"/projects/steiflab/archive/data/imaging/{chip}/NozzleImages/{run}\"\n",
    "main_img_directory = f\"/projects/steiflab/archive/data/imaging/{chip}/CellenONEImages/{run}\" # for cellenONE\n",
    "main_mask_directory = f\"/projects/steiflab/scratch/leli/{chip}/{run}/rcnn_output_masks\"\n",
    "out_folder = f'{chip}/{run}/tracked'\n",
    "\n",
    "# Load images\n",
    "imgs, img_names = load_images_from_directory(main_img_directory)\n",
    "\n",
    "# Load masks\n",
    "masks = load_masks_from_directory(main_mask_directory, imgs[0].shape, fix_overlap = True, overlap_threshold = 0.5)\n",
    "\n",
    "print(\"Images shape:\", imgs.shape)\n",
    "print(\"Masks shape:\", masks.shape)\n",
    "\n",
    "# Ensure the shape matches the required format: (time, y, x)\n",
    "imgs = imgs.reshape(-1, imgs.shape[1], imgs.shape[2])\n",
    "masks = masks.reshape(-1, masks.shape[1], masks.shape[2])\n",
    "\n",
    "imgs, masks, ind_to_remove = remove_empty_frame(imgs, masks)\n",
    "\n",
    "print(\"Images shape:\", imgs.shape)\n",
    "print(\"Masks shape:\", masks.shape)\n",
    "\n",
    "\n",
    "'''# Load a pretrained model\n",
    "# or from a local folder\n",
    "# model = Trackastra.from_folder('path/my_model_folder/', device=device)\n",
    "model = Trackastra.from_pretrained(\"general_2d\", device=device)\n",
    "\n",
    "# Track the cells\n",
    "track_graph = model.track(imgs, masks, mode=\"greedy\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "\n",
    "# Write to cell tracking challenge format\n",
    "ctc_tracks, masks_tracked = graph_to_ctc(\n",
    "      track_graph,\n",
    "      masks,\n",
    "      outdir=out_folder,\n",
    ")'''\n",
    "\n",
    "\n",
    "## create a file that connects tiffs with the images\n",
    "tifs = sorted([t for t in os.listdir(out_folder) if t.endswith(\".tif\")])\n",
    "img_names_new = np.delete(img_names, ind_to_remove, axis = 0)\n",
    "link_file = pd.DataFrame({\"tifs\": tifs, \"imgs\": img_names_new})\n",
    "link_file.to_csv(os.path.join(out_folder, \"tif_to_img.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "\n",
    "# Function to create a video from the saved PNGs\n",
    "def create_video(output_dir, output_video, num_frames, width, height, fps=5, n_img = 2, frames_to_process = None):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video, fourcc, fps, (width*n_img+10*(n_img-1), height))\n",
    "\n",
    "    for frame_idx in range(num_frames):\n",
    "\n",
    "        # Check frame range\n",
    "        if frames_to_process is not None: \n",
    "            if frame_idx not in frames_to_process:\n",
    "                continue\n",
    "\n",
    "        if not os.path.isfile(os.path.join(output_dir, f'man_track{frame_idx:04d}.png')): \n",
    "            raise ValueError(f\"This file does not exists {os.path.join(output_dir, f'man_track{frame_idx:04d}.png')}\")\n",
    "\n",
    "        frame_path = os.path.join(output_dir, f'man_track{frame_idx:04d}.png')\n",
    "        frame = cv2.imread(frame_path)\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    video_writer.release()\n",
    "    print(f'Video saved as {output_video}')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "def process_frames(imgs, tracking_dir, output_dir, frames_to_process = None):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # Load images if `imgs` is a file path\n",
    "    if os.path.isfile(imgs):\n",
    "        imgs = np.load(imgs)\n",
    "        #print(f\"Loaded images from {imgs}\")\n",
    "\n",
    "    tif_files = [file for file in os.listdir(tracking_dir) if not file.startswith(\"._\") and file.endswith(\"tif\")]\n",
    "    tif_files = sorted(tif_files)\n",
    "    #print(f\"Found {len(tif_files)} tif files\")\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        #print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "    for i, file in enumerate(tif_files):\n",
    "        #print(f\"Processing file {i}: {file}\")\n",
    "\n",
    "        # Check frame range\n",
    "        if frames_to_process is not None: \n",
    "            if i not in frames_to_process:\n",
    "                continue\n",
    "            \n",
    "        #print(f\"Frame {i} is within the specified range\")\n",
    "\n",
    "        # Read the tiff file\n",
    "        tif = tiff.imread(os.path.join(tracking_dir, file))\n",
    "        if tif is None:\n",
    "            print(f\"Error reading label image: {os.path.join(tracking_dir, file)}\")\n",
    "            continue\n",
    "\n",
    "        # Process the corresponding image\n",
    "        img = imgs[i]\n",
    "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)  # Normalize the image to 8-bit range\n",
    "        img = img.astype(np.uint8)  # Convert to 8-bit for visualization\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        annotated_img = original_img.copy()\n",
    "\n",
    "        unique_labels = np.unique(tif)\n",
    "        #print(f\"Unique labels found: {unique_labels}\")\n",
    "\n",
    "        for label in unique_labels:\n",
    "            if label == 0:  # Skip the background\n",
    "                continue\n",
    "\n",
    "            # Create a mask for the current label\n",
    "            mask = np.zeros(tif.shape, dtype=np.uint8)\n",
    "            mask[tif == label] = 255\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #print(f\"Found {len(contours)} contours for label {label}\")\n",
    "\n",
    "            # Draw contours and label\n",
    "            for contour in contours:\n",
    "                cv2.drawContours(annotated_img, [contour], -1, (57, 255, 20), 1)  # Neon green color with thinner trace\n",
    "                # Get the bounding box for placing the label\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.putText(annotated_img, str(label), (x, y - 10), font, 0.5, (0, 0, 255), 1, cv2.LINE_AA)  # Purple\n",
    "\n",
    "        # Create a white space (column) between the images\n",
    "        white_space = np.ones((original_img.shape[0], 10, 3), dtype=np.uint8) * 255\n",
    "\n",
    "        # Combine the original and annotated images with white space in between\n",
    "        combined_img = cv2.hconcat([original_img, white_space, annotated_img])\n",
    "        #print(f\"Combined image shape: {combined_img.shape}\")\n",
    "\n",
    "        output_path = os.path.join(output_dir, file.replace(\".tif\", \".png\"))\n",
    "        # Save the output image\n",
    "        # print(f\"Save and complete file {i}: {file}\")\n",
    "        if not cv2.imwrite(output_path, combined_img):\n",
    "            print(f\"Error saving image: {output_path}\")\n",
    "        else:\n",
    "            print(f\"Saved image for frame: {i} at {output_path}\")\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predefined colors with names\n",
    "color_map = {\n",
    "    'red': (255, 0, 0),\n",
    "    'green': (0, 255, 0),\n",
    "    'blue': (0, 0, 255),\n",
    "    'cyan': (0, 255, 255),\n",
    "    'magenta': (255, 0, 255),\n",
    "    'yellow': (255, 255, 0),\n",
    "    'orange': (255, 165, 0),\n",
    "    'purple': (128, 0, 128),\n",
    "    'pink': (255, 192, 203),\n",
    "    'lime': (0, 255, 0)\n",
    "}\n",
    "\n",
    "def get_color_name(index):\n",
    "    \"\"\"\n",
    "    Get the color name and RGB values based on the index.\n",
    "\n",
    "    Parameters:\n",
    "    - index: int, index of the color in the color map.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (color_name, color_rgb), where color_name is the name of the color and color_rgb is the RGB tuple.\n",
    "    \"\"\"\n",
    "    color_names = list(color_map.keys())\n",
    "    color_name = color_names[index % len(color_map)]\n",
    "    color_rgb = color_map[color_name]\n",
    "    return color_name, color_rgb\n",
    "\n",
    "def display_colored_labels(path, labels):\n",
    "    \"\"\"\n",
    "    Display an image with each label colored uniquely.\n",
    "\n",
    "    Parameters:\n",
    "    - path: str, path to the directory containing TIFF files or a single TIFF file.\n",
    "    - labels: list of int, list of labels to be colored.\n",
    "\n",
    "    Output:\n",
    "    - Display the image with colored labels.\n",
    "    \"\"\"\n",
    "    # Create a blank canvas for the final image\n",
    "    final_image = None\n",
    "\n",
    "    def process_tif_file(file_path):\n",
    "        nonlocal final_image\n",
    "        tif = tiff.imread(file_path)\n",
    "\n",
    "        # Initialize the final image if it hasn't been already\n",
    "        if final_image is None:\n",
    "            final_image = np.zeros((tif.shape[0], tif.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "        # Color each label with a unique color\n",
    "        for i, label in enumerate(labels):\n",
    "            color_name, color_rgb = get_color_name(i)\n",
    "            print(f\"Label {label} is colored with {color_name} (RGB: {color_rgb})\")\n",
    "            mask = (tif == label)\n",
    "            final_image[mask] = color_rgb\n",
    "\n",
    "    # Check if the path is a directory or a single file\n",
    "    if os.path.isdir(path):\n",
    "        # Process each TIFF file in the directory\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".tif\"):\n",
    "                file_path = os.path.join(path, file)\n",
    "                process_tif_file(file_path)\n",
    "    else:\n",
    "        # Process the single TIFF file\n",
    "        process_tif_file(path)\n",
    "\n",
    "    # Display the final image\n",
    "    if final_image is not None:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(\"Colored Labels\")\n",
    "        plt.imshow(final_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No TIFF files found or processed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing tracking results (TIFF files and text file)\n",
    "tracking_dir = f\"/projects/steiflab/scratch/leli/trackastra/{out_folder}_postprocessed_2.0\"\n",
    "print(f\"{os.path.isdir(tracking_dir)}\")\n",
    "# Create an output directory for PNGs\n",
    "output_dir = f\"/projects/steiflab/scratch/leli/trackastra/{out_folder}_postprocessed_2.0_imgs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each frame\n",
    "#total_frame_num = len([file for file in os.listdir(main_img_directory) if file.startswith(\"Image_\") and file.endswith(\".png\")])\n",
    "total_frame_num = len([filename for filename in os.listdir(main_img_directory) if filename.endswith(\"_htert_Run.png\") and not filename.startswith(\"._\") and \"Printed\" not in filename])\n",
    "act_rcnn_inds = [i+1 for i in range(total_frame_num) if i not in ind_to_remove] # here we are tying to find the corresponding frame index that matches with the rcnn results\n",
    "assert len([file for file in os.listdir(tracking_dir) if not file.startswith(\"._\") and file.endswith(\"tif\")]) == len(act_rcnn_inds)\n",
    "\n",
    "start = 3274\n",
    "end = 3757\n",
    "frames_to_process = [i for i, act in enumerate(act_rcnn_inds) if act >= start and act <= end] # here if teh act rcnn index is in range then we include the 0-starting index which will be used to index the ti files later\n",
    "print(frames_to_process)\n",
    "\n",
    "process_frames(imgs, tracking_dir, output_dir, frames_to_process = None)\n",
    "print(f\"Process frames done!\")\n",
    "\n",
    "# Create a video from the saved PNGs\n",
    "'''print(f\"These are the tiffs that should be in the ground truth\")\n",
    "output_video = f'/projects/steiflab/scratch/leli/trackastra/postprocessing/tracked_1.0_imgs_pp/tracked_video_val.mp4'\n",
    "height, width = imgs.shape[1], imgs.shape[2]  # Get height and width from images\n",
    "create_video(output_dir, output_video, imgs.shape[0], width, height, fps=3, frames_to_process = frames_to_process)'''\n",
    "\n",
    "height, width = imgs.shape[1], imgs.shape[2]  # Get height and width from images\n",
    "output_video = f'/projects/steiflab/scratch/leli/trackastra/{out_folder}_postprocessed_2.0_imgs/tracked_video_full.mp4'\n",
    "create_video(output_dir, output_video, imgs.shape[0], width, height, fps=3, frames_to_process = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Track to Well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since cellenONE format is different we just want to change how we get the last frame and then we will move on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from skimage.measure import label, regionprops\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def load_resize_combine_display(tif_path, png_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Load a TIFF image and a PNG image, resize the PNG to match the TIFF dimensions, and combine/display both images.\n",
    "\n",
    "    Parameters:\n",
    "    - tif_path: str, path to the TIFF image file.\n",
    "    - png_path: str, path to the PNG image file.\n",
    "    - output_path: str, path to save the combined image (optional).\n",
    "    \"\"\"\n",
    "    # Load the TIFF file\n",
    "    tif_image = tiff.imread(tif_path)\n",
    "    \n",
    "    # Load the PNG file\n",
    "    png_image = Image.open(png_path)\n",
    "    \n",
    "    # Resize the PNG file to match the TIFF dimensions\n",
    "    png_resized = png_image.resize((tif_image.shape[1], tif_image.shape[0]), Image.LANCZOS)\n",
    "    \n",
    "    # Convert the resized PNG image to a numpy array\n",
    "    png_array = np.array(png_resized)\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display the TIFF image with viridis colormap\n",
    "    ax[0].imshow(tif_image, cmap='viridis')\n",
    "    ax[0].set_title('TIFF Image (Viridis)')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    # Display the resized PNG image\n",
    "    ax[1].imshow(png_array)\n",
    "    ax[1].set_title('Resized PNG Image')\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the combined image if output_path is provided\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "    \n",
    "    # Show the combined image\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def find_highest_object(frame):\n",
    "    \"\"\"\n",
    "    Find the object that has the highest y value within the bottom quarter of the image.\n",
    "\n",
    "    Parameters:\n",
    "    - frame: numpy array, the pixel matrix where entries are object assignments.\n",
    "\n",
    "    Returns:\n",
    "    - highest_object_id: int, the ID of the object that is closest to the bottom and within the bottom quarter of the image.\n",
    "    - highest_y: int, the highest y-coordinate of the object.\n",
    "    \"\"\"\n",
    "    # Calculate the threshold for the bottom quarter\n",
    "    threshold = 2.5 * frame.shape[0] // 4\n",
    "    \n",
    "    # Label the objects in the frame\n",
    "    unique_labels = np.unique(frame)\n",
    "    \n",
    "    # Initialize variables to keep track of the highest object\n",
    "    highest_object_id = 0\n",
    "    highest_y = 0\n",
    "    \n",
    "    # Iterate through each labeled region\n",
    "    for label in unique_labels:\n",
    "        if label == 0: \n",
    "            continue \n",
    "        #print(f\"iterating through the find highest y value fucntion and the current rehion is {label}\")\n",
    "\n",
    "        binary_mask = (frame == label).astype(np.uint8)\n",
    "        region = regionprops(binary_mask)[0]\n",
    "        # Get the coordinates of the region\n",
    "        coords = region.coords\n",
    "        # Find the maximum y-coordinate of the region\n",
    "        max_y = coords[:, 0].max()\n",
    "        #print(f\"The max y coor is {max_y} and the threshold is {threshold} with the current highest is {highest_y} for track id: {label}\")\n",
    "        # Check if the maximum y-coordinate is within the bottom quarter\n",
    "        if max_y >= threshold and max_y > highest_y:\n",
    "            highest_y = max_y\n",
    "            highest_object_id = label\n",
    "    \n",
    "    return highest_object_id, highest_y\n",
    "\n",
    "def numerical_sort(value):\n",
    "    \"\"\"\n",
    "    Extracts the numeric part from the filename for sorting.\n",
    "    Assumes that the filename format is '<number>_htert_Run'.\n",
    "    \"\"\"\n",
    "    parts = re.findall(r'\\d+', value)\n",
    "    return int(parts[0]) if parts else value\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import tifffile as tiff\n",
    "\n",
    "def link_track_to_well(logfile_directory, tracked_tif_directory, fluro_directory, linkfile_directory, output_directory=None):\n",
    "\n",
    "    linkfile = pd.read_csv(linkfile_directory)\n",
    "    linkfile = linkfile.sort_values(by='tifs').reset_index(drop=True)\n",
    "    logfile = pd.read_csv(logfile_directory)\n",
    "    gr_logfile = logfile.groupby(['ImageFile'])\n",
    "\n",
    "    # Filter out groups where the key contains \"samplename\"\n",
    "    filtered_groups = [name for name in gr_logfile.groups if \"samplename\" not in name]\n",
    "\n",
    "    # Get the number of such groups\n",
    "    number_of_filtered_groups = len(filtered_groups)\n",
    "    print(f\"There are {number_of_filtered_groups} groups where 'ImageFile' does not contain 'samplename'.\")\n",
    "\n",
    "    final_dict = {\n",
    "        \"track_ID\": [], \n",
    "        \"after_dispense_frame\": [], \n",
    "        \"last_tracked_frame\": [],\n",
    "        \"last_tracked_tif\": [],\n",
    "        \"row\": [],\n",
    "        \"col\": []}\n",
    "    \n",
    "\n",
    "    for (ImageFile), group in gr_logfile:\n",
    "        if \"samplename\" in ImageFile[0]: continue\n",
    "        print(f\"ImageFile is {ImageFile[0]}\")\n",
    "\n",
    "        # Use regex to find the numbers following 'R' and 'C'\n",
    "        match = re.search(r'_R(\\d+)_C(\\d+)', ImageFile[0])\n",
    "        if match:\n",
    "            r = int(match.group(1))\n",
    "            c = int(match.group(2))\n",
    "        else:\n",
    "            raise ValueError(\"Filename format is incorrect\")\n",
    "        \n",
    "        fluro_img = tiff.imread(os.path.join(fluro_directory, f\"C{c:02d}\", f\"R{r:02d}_C{c:02d}_0000_00_Cyan.tif\"))\n",
    "\n",
    "        # Use regex to find the numbers following 'R' and 'C'\n",
    "        match = re.search(r'(\\d+)_Printed', ImageFile[0])\n",
    "        if match:\n",
    "            after_dispense_frame = str(match.group(1)) + \"_htert_Run\"\n",
    "        else:\n",
    "            raise ValueError(\"Filename format is incorrect\")\n",
    "\n",
    "        print(f\"The current iteration has r: {r}, c: {c}, with the after dispense frame being {after_dispense_frame}\")\n",
    "\n",
    "        # Establish the values to be inputted into the dataframe\n",
    "        track_ID = 0  # Default meaning no track associated\n",
    "        last_tracked_frame = after_dispense_frame \n",
    "        last_tracked_tif = \"\"  # Empty because the image may not have a corresponding tif file\n",
    "\n",
    "        # Obtain the 3 frames right before the frame after dispense \n",
    "        tif_to_consider = []\n",
    "        img_to_consider = []\n",
    "        frames_before = [f for f in linkfile[\"imgs\"] if numerical_sort(f) <= numerical_sort(after_dispense_frame)]\n",
    "        if len(frames_before) == 0: \n",
    "            print(f\"There are zero frames including the current after dispense frame one {after_dispense_frame}\")\n",
    "        else: \n",
    "            prev_closest_frame = sorted(frames_before, key=numerical_sort, reverse=True)[0]\n",
    "            tif_after_dispense = linkfile.loc[linkfile[\"imgs\"] == prev_closest_frame][\"tifs\"]\n",
    "            if len(tif_after_dispense) != 0:\n",
    "                i = tif_after_dispense.index[0]\n",
    "                if i >= 2: \n",
    "                    a = sorted(linkfile.iloc[i-2:i+1]['tifs'], key=numerical_sort, reverse=True)\n",
    "                    b = sorted(linkfile.iloc[i-2:i+1]['imgs'], key=numerical_sort, reverse=True)\n",
    "                    tif_to_consider = sorted([tif for tif, img in zip(a, b) if numerical_sort(after_dispense_frame) - numerical_sort(img) <= 2], reverse=True)\n",
    "                    img_to_consider = sorted([img for tif, img in zip(a, b) if numerical_sort(after_dispense_frame) - numerical_sort(img) <= 2], reverse=True)\n",
    "                elif i != 0: \n",
    "                    a = sorted(linkfile.iloc[:i+1]['tifs'], key=numerical_sort, reverse=True)\n",
    "                    b = sorted(linkfile.iloc[:i+1]['imgs'], key=numerical_sort, reverse=True)\n",
    "                    tif_to_consider = sorted([tif for tif, img in zip(a, b) if numerical_sort(after_dispense_frame) - numerical_sort(img) <= 2], reverse=True)\n",
    "                    img_to_consider = sorted([img for tif, img in zip(a, b) if numerical_sort(after_dispense_frame) - numerical_sort(img) <= 2], reverse=True)\n",
    "\n",
    "            print(f\"The img to consider is {img_to_consider}\")\n",
    "\n",
    "            for tif_name, img_name in zip(tif_to_consider, img_to_consider):\n",
    "\n",
    "                tracked_tif = tiff.imread(os.path.join(tracked_tif_directory, tif_name))\n",
    "                track_ID, highest_y = find_highest_object(tracked_tif)\n",
    "                last_tracked_frame = img_name\n",
    "                last_tracked_tif = tif_name\n",
    "                if track_ID: \n",
    "                    break  # Since the filename is sorted from later frames to earlier, stop if we find one that fits into our threshold\n",
    "\n",
    "        final_dict[\"track_ID\"].append(int(track_ID))\n",
    "        final_dict[\"after_dispense_frame\"].append(after_dispense_frame)\n",
    "        final_dict[\"last_tracked_frame\"].append(last_tracked_frame)\n",
    "        final_dict[\"last_tracked_tif\"].append(last_tracked_tif)\n",
    "        final_dict[\"row\"].append(r)\n",
    "        final_dict[\"col\"].append(c)\n",
    "\n",
    "    if output_directory: \n",
    "        pd.DataFrame(final_dict).to_csv(os.path.join(output_directory, \"track_to_well_unfiltered.csv\"), index=False)\n",
    "    \n",
    "    return pd.DataFrame(final_dict)\n",
    "\n",
    "\n",
    "logfile_directory = '/projects/steiflab/scratch/leli/A138856A/htert_20230822_131349_843.Run/record.csv'\n",
    "tracked_tif_directory = '/projects/steiflab/scratch/leli/trackastra/A138856A/htert_20230822_131349_843.Run/tracked_postprocessed_2.0'\n",
    "fluro_directory = '/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000/'\n",
    "linkfile_directory = '/projects/steiflab/scratch/leli/trackastra/A138856A/htert_20230822_131349_843.Run/tracked/tif_to_img.csv'\n",
    "\n",
    "df = link_track_to_well(logfile_directory, tracked_tif_directory, fluro_directory, linkfile_directory, output_directory = '/projects/steiflab/scratch/leli/A138856A/htert_20230822_131349_843.Run/track_to_well')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the track to well file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_track_ids(df, track_info, output_directory):\n",
    "\n",
    "    # Process each unique track ID with multiple rows\n",
    "    track_id_counts = df['track_ID'].value_counts()\n",
    "    multiple_row_track_ids = track_id_counts[track_id_counts > 1].index\n",
    "\n",
    "    for track_id in multiple_row_track_ids:\n",
    "        if track_id <= 0:\n",
    "            continue\n",
    "\n",
    "        track_df = df[df['track_ID'] == track_id]\n",
    "        \n",
    "        # Get the corresponding track info row\n",
    "        track_info_row = track_info[track_info['Track_ID'] == track_id]\n",
    "        if track_info_row.empty:\n",
    "            print(f\"Track ID {track_id}: No matching track info found.\")\n",
    "            continue\n",
    "\n",
    "        # Calculate the distance to the end value for each row in the track_df\n",
    "        end_value = track_info_row['End'].values[0]\n",
    "        df.loc[track_df.index, 'distance_to_end'] = [abs(numerical_sort(i) - end_value) for i in track_df['last_tracked_tif']]\n",
    "        \n",
    "        # Find the row with the minimum distance to the end value\n",
    "        closest_row_idx = df.loc[track_df.index, 'distance_to_end'].idxmin()\n",
    "        \n",
    "        # Label all other rows with -1\n",
    "        df.loc[track_df.index.difference([closest_row_idx]), 'track_ID'] = -1\n",
    "\n",
    "\n",
    "    # Save the processed DataFrame if an output directory is provided\n",
    "    if output_directory:\n",
    "        if \"distance_to_end\" in list(df.columns): df.drop(columns=['distance_to_end'], inplace=True)\n",
    "        df.to_csv(os.path.join(output_directory, \"track_to_well_pp.csv\"), index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.DataFrame(...)  # Your df dataframe\n",
    "track_info = pd.read_csv('/projects/steiflab/scratch/leli/trackastra/A138856A/htert_20230822_131349_843.Run/tracked_postprocessed_2.0/man_track.txt', sep='\\s+', header=None, names=['Track_ID', 'Start', 'End', 'Mother'])  # Your track_info dataframe\n",
    "processed_df = process_track_ids(df, track_info, output_directory='/projects/steiflab/scratch/leli/A138856A/htert_20230822_131349_843.Run/track_to_well')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_unique_track_ids(df):\n",
    "    # Filter out non-zero track IDs\n",
    "    positive_nonzero_track_ids = df[df['track_ID'] > 0]['track_ID']\n",
    "\n",
    "    # Get the value counts of these track IDs\n",
    "    track_id_counts = positive_nonzero_track_ids.value_counts()\n",
    "\n",
    "    # Display the track IDs and their counts\n",
    "    print(\"Unique positive non-zero track IDs and their counts:\")\n",
    "    print(track_id_counts)\n",
    "\n",
    "    # Verify that each track ID has only one row\n",
    "    duplicate_tracks = track_id_counts[track_id_counts > 1]\n",
    "    if duplicate_tracks.empty:\n",
    "        print(\"All positive non-zero track IDs have only one row.\")\n",
    "    else:\n",
    "        print(\"Some track IDs have duplicates:\")\n",
    "        print(duplicate_tracks)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "display_unique_track_ids(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Read the TIFF file\n",
    "tif_file_path = '/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000/C60/R20_C60_0000_00_Cyan.tif'\n",
    "image = tiff.imread(tif_file_path)\n",
    "\n",
    "# Step 2: Display the image with viridis colormap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image, cmap='viridis')\n",
    "plt.colorbar()  # Optional: Add a colorbar to show the intensity scale\n",
    "plt.title('TIFF Image with Viridis Colormap')\n",
    "plt.axis('off')  # Optional: Hide the axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets analyze it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we can see there are 40 out of 412 wells that do not associate with any "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = processed_df['track_ID'].value_counts()\n",
    "duplicate_values = value_counts[value_counts > 1]\n",
    "print(duplicate_values)\n",
    "print(len(np.unique(processed_df['track_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1313 missing tracks that are not passed.\n",
    "\n",
    "Intepretation of this group: \n",
    "\n",
    "    - tracking mistake  --> How we can try our best to filter this out is to check the last frame this track happened and if it is not in the bottom quater of the image then we discard it\n",
    "    \n",
    "    - discarded --> This is what we wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(np.unique(processed_df['track_ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_info = pd.read_csv('/projects/steiflab/scratch/leli/trackastra/A138856A/htert_20230822_131349_843.Run/tracked_postprocessed_2.0/man_track.txt', sep='\\s+', header=None, names=['Index', 'Start', 'End', 'Mother'])\n",
    "missing_track_ids = list(set(track_info['Index']).difference(set(processed_df['track_ID'])))\n",
    "print(missing_track_ids)\n",
    "print(len(missing_track_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 765 that are discarded and there are 603 that are tracking mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "def end_to_tif_filename(end_value, base_folder):\n",
    "    # Example conversion logic, you might need to adjust the format\n",
    "    return os.path.join(base_folder, f\"man_track{end_value:04d}.tif\")\n",
    "\n",
    "def is_in_bottom_quarter(coords, image_shape):\n",
    "    bottom_threshold = 5 * image_shape[0] // 8\n",
    "    return np.all(coords[:, 0] >= bottom_threshold)\n",
    "\n",
    "def check_missing_tracks(missing_track_ids, man_track, processed, base_folder):\n",
    "    # Lists to categorize track IDs\n",
    "    not_found_tracks = []\n",
    "    bottom_quarter_tracks = []\n",
    "    not_bottom_quarter_tracks = []\n",
    "    \n",
    "    for track_id in missing_track_ids:\n",
    "        end_value = man_track.loc[man_track['Index'] == track_id, 'End'].values[0]\n",
    "        tif_filename = end_to_tif_filename(end_value, base_folder)\n",
    "        \n",
    "        if not os.path.exists(tif_filename):\n",
    "            raise FileNotFoundError(f\"TIFF file {tif_filename} does not exist.\")\n",
    "        \n",
    "        # Load the TIFF file\n",
    "        tiff_image = tiff.imread(tif_filename)\n",
    "        \n",
    "        # Check if the track ID exists in the TIFF image\n",
    "        if track_id not in np.unique(tiff_image):\n",
    "            not_found_tracks.append(track_id)\n",
    "        else:\n",
    "            # Get the coordinates of the object\n",
    "            coords = np.column_stack(np.where(tiff_image == track_id))\n",
    "            \n",
    "            # Check if the object is in the bottom quarter\n",
    "            if is_in_bottom_quarter(coords, tiff_image.shape):\n",
    "                bottom_quarter_tracks.append(track_id)\n",
    "            else:\n",
    "                not_bottom_quarter_tracks.append(track_id)\n",
    "    \n",
    "    return not_found_tracks, bottom_quarter_tracks, not_bottom_quarter_tracks\n",
    "\n",
    "# Assuming the base_folder is where the TIFF files are located\n",
    "base_folder = '/projects/steiflab/scratch/leli/trackastra/A138856A/htert_20230822_131349_843.Run/tracked_postprocessed_2.0'\n",
    "\n",
    "# Check the missing tracks\n",
    "not_found_tracks, bottom_quarter_tracks, not_bottom_quarter_tracks = check_missing_tracks(missing_track_ids, track_info, processed_df, base_folder)\n",
    "\n",
    "# Output results\n",
    "print(f\"Track IDs not found in their end frame: {not_found_tracks}\")\n",
    "print(f\"Track IDs entirely in the bottom quarter of their end frame: {bottom_quarter_tracks} wiht length {len(bottom_quarter_tracks)}\")\n",
    "print(f\"Track IDs NOT entirely in the bottom quarter of their end frame: {not_bottom_quarter_tracks} with length {len(not_bottom_quarter_tracks)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "print(f\"Here are ten picked out from the bottom quarter: {sorted(random.sample([i for i in bottom_quarter_tracks if i < 500], 10))}\")\n",
    "print(f\"Here are ten picked out from the NOT bottom quarter: {sorted(random.sample([i for i in not_bottom_quarter_tracks if i  < 500], 10))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can conclude that ALL the ones picked out in the bottom quater are good tracks that travel down with no issue\n",
    "\n",
    "Here we can also conclude that 70% of the ones that we put in the not in bottom quarter are mistakes like label switching and 30% of them are just tracks that ends abruptly do not know where they went since that is the last frame they were ever observed\n",
    "\n",
    "The rest of the analysis will be conducted in the feature_extraction.ipynb file the goal is to have the same analysis done to try to find a way to distinguish between the two or to train a tree where we can logically distinguish the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(np.unique(processed_df['track_ID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for isolated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = pd.read_csv('/projects/steiflab/scratch/leli/A138856A/htert_20230822_131349_843.Run/isolated_metadata.csv')  # Load your DataFrame if needed\n",
    "print(df.shape)\n",
    "# Count unique values in the 'Prediction' column\n",
    "prediction_counts = df['Type'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(prediction_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results\n",
    "sampled_images = {}\n",
    "\n",
    "# Loop through each unique value in the 'Type' column\n",
    "for type_value in df['Type'].unique():\n",
    "    # Filter the DataFrame for the current Type value\n",
    "    filtered_df = df[df['Type'] == type_value]\n",
    "    \n",
    "    # Sample 10 values from the 'Fluro_image' column\n",
    "    sampled_images[type_value] = filtered_df['Fluro_image'].sample(n=10, random_state=42).tolist()\n",
    "\n",
    "# Print the results\n",
    "for type_value, images in sampled_images.items():\n",
    "    print(f\"Type: {type_value}\")\n",
    "    print(f\"Sampled Fluro_image values: {images}\")\n",
    "    print(\"\\n\")  # Add a newline for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread\n",
    "import numpy as np\n",
    "\n",
    "# Function to display a .tif image using the Viridis colormap\n",
    "def display_tif_image(file_path):\n",
    "    # Read the .tif image\n",
    "    image = imread(file_path)\n",
    "    \n",
    "    # Display the image with the Viridis colormap\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Image: {os.path.basename(file_path)}\")\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "# Loop through the dictionary and display each image\n",
    "for type_value, images in sampled_images.items():\n",
    "    print(f\"Displaying images for Type: {type_value}\")\n",
    "    for image_path in images:\n",
    "        display_tif_image(os.path.join(\"/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000\", image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging between sequence data and fluoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "t_df = pd.read_csv('/projects/steiflab/scratch/leli/A138856A/htert_20230822_131349_843.Run/isolated_metadata.csv')\n",
    "#seq_df = pd.read_csv('/projects/steiflab/scratch/glchang/other/leon/A138856.tsv', sep = '\\t')\n",
    "\n",
    "# Initialize a list to store rows\n",
    "seq_df = []\n",
    "\n",
    "# Open and read the TSV file using csv.reader\n",
    "with open('/projects/steiflab/scratch/glchang/other/leon/A138856.tsv', mode='r') as file:\n",
    "    reader = csv.reader(file, delimiter=' ')\n",
    "    \n",
    "    for row in reader:\n",
    "        seq_df.append(row)\n",
    "seq_df = pd.DataFrame(seq_df)\n",
    "\n",
    "seq_df.columns = seq_df.iloc[0]  # Set the first row as the header\n",
    "seq_df = seq_df[1:]  # Remove the first row from the data\n",
    "seq_df.reset_index(drop=True, inplace=True)  # Reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df['row']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'row' and 'col' columns in seq_df to int64\n",
    "seq_df['row'] = seq_df['row'].astype(int)\n",
    "seq_df['col'] = seq_df['col'].astype(int)\n",
    "seq_df['total_reads'] = seq_df['total_reads'].astype(int)\n",
    "# Perform the merge with the converted columns\n",
    "merged_df = pd.merge(t_df, seq_df, left_on=['R', 'C'], right_on=['row', 'col'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['total_reads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df' is your DataFrame that contains 'total_reads' and 'Type' columns\n",
    "# Adjust the DataFrame name if needed\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Type', y='total_reads', data=merged_df)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot of Total Reads by Type')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Total Reads')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame that contains 'total_reads', 'Fluro_image', and 'cell_condition' columns\n",
    "\n",
    "# Step 1: Calculate the 80th percentile of total_reads\n",
    "percentile_80 = merged_df['total_reads'].quantile(0.20)\n",
    "ncc_cutoff = 113014 + 72160\n",
    "# Step 2: Split the data into two groups based on the 80th percentile\n",
    "below_80th = merged_df[merged_df['total_reads'] <= ncc_cutoff]\n",
    "above_80th = merged_df[merged_df['total_reads'] > ncc_cutoff]\n",
    "\n",
    "# Step 3: Randomly sample 10 values from the 'Fluro_image' column in each group\n",
    "below_80th_sample = below_80th.sample(n=10)\n",
    "above_80th_sample = above_80th.sample(n=10)\n",
    "\n",
    "# Function to display a .tif image using the Viridis colormap\n",
    "def display_tif_image(file_path, cell_condition, experimental_condition):\n",
    "    # Read the .tif image\n",
    "    image = imread(file_path)\n",
    "    \n",
    "    # Calculate the maximum pixel intensity\n",
    "    max_intensity = image.max()\n",
    "    \n",
    "    # Display the image with the Viridis colormap\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Print the max intensity on the image\n",
    "    plt.text(0.05, 0.95, f\"Max Intensity: {max_intensity}\", color='white', fontsize=12,\n",
    "             ha='left', va='top', transform=plt.gca().transAxes, bbox=dict(facecolor='black', alpha=0.5))\n",
    "    \n",
    "    plt.title(f\"Image: {os.path.basename(file_path)}\\nCell Condition: {cell_condition}\\n Exp condition: {experimental_condition}\")\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "# Display images and corresponding cell conditions below the 80th percentile\n",
    "print(\"Displaying images below the ncc_cutoff:\")\n",
    "for _, row in below_80th_sample.iterrows():\n",
    "    image_file = row['Fluro_image']\n",
    "    cell_condition = row['cell_condition']\n",
    "    experimental_condition = row['experimental_condition']\n",
    "    display_tif_image(os.path.join(\"/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000\", image_file), cell_condition, experimental_condition)\n",
    "\n",
    "# Display images and corresponding cell conditions above the 80th percentile\n",
    "print(\"Displaying images above the ncc_cutoff:\")\n",
    "for _, row in above_80th_sample.iterrows():\n",
    "    image_file = row['Fluro_image']\n",
    "    cell_condition = row['cell_condition']\n",
    "    experimental_condition = row['experimental_condition']\n",
    "    display_tif_image(os.path.join(\"/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000\", image_file), cell_condition, experimental_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame that contains the 'total_reads' column\n",
    "\n",
    "# Step 1: Calculate the 20th percentile of total_reads\n",
    "percentile_20 = merged_df['total_reads'].quantile(0.20)\n",
    "percentile_80 = merged_df['total_reads'].quantile(0.80)\n",
    "# Step 2: Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_df['total_reads'], bins=30, color='blue', edgecolor='black')\n",
    "\n",
    "# Step 3: Add a vertical line at the 20th percentile\n",
    "plt.axvline(percentile_20, color='red', linestyle='dashed', linewidth=2, label=f'20th Percentile: {percentile_20:.2f}')\n",
    "plt.axvline(percentile_80, color='red', linestyle='dashed', linewidth=2, label=f'80th Percentile: {percentile_80:.2f}')\n",
    "\n",
    "# Step 4: Add title and labels\n",
    "plt.title('Histogram of Total Reads with 20th Percentile')\n",
    "plt.xlabel('Total Reads')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tifffile import imread\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame that contains 'total_reads', 'Fluro_image', and 'cell_condition' columns\n",
    "\n",
    "# Step 1: Calculate the 80th percentile of total_reads\n",
    "ncc_cutoff = 113014   + 72160\n",
    "\n",
    "# Step 2: Split the data into two groups based on the ncc_cutoff\n",
    "below_80th = merged_df[merged_df['total_reads'] <= ncc_cutoff]\n",
    "above_80th = merged_df[merged_df['total_reads'] > ncc_cutoff]\n",
    "\n",
    "# Step 3: Calculate the Z-score of max pixel intensity for each image\n",
    "def get_max_intensity_zscore(row):\n",
    "    image_file = os.path.join(\"/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000\", row['Fluro_image'])\n",
    "    image = imread(image_file)\n",
    "    max_intensity = image.max()\n",
    "    mean_intensity = np.mean(image)\n",
    "    std_intensity = np.std(image)\n",
    "    \n",
    "    # Calculate the Z-score for the max intensity\n",
    "    z_score = (max_intensity - mean_intensity) / std_intensity if std_intensity > 0 else 0\n",
    "    return z_score\n",
    "\n",
    "# Apply the function to calculate Z-score for max intensity for each group\n",
    "below_80th = below_80th.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "above_80th = above_80th.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "below_80th.loc[:, 'max_intensity_zscore'] = below_80th.apply(get_max_intensity_zscore, axis=1)\n",
    "above_80th.loc[:, 'max_intensity_zscore'] = above_80th.apply(get_max_intensity_zscore, axis=1)\n",
    "\n",
    "# Combine the results into a single DataFrame for plotting\n",
    "plot_data = pd.concat([\n",
    "    below_80th[['max_intensity_zscore']].assign(group='Below ncc_cutoff'),\n",
    "    above_80th[['max_intensity_zscore']].assign(group='Above ncc_cutoff')\n",
    "])\n",
    "\n",
    "# Step 4: Create a violin plot to visualize the Z-score distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='group', y='max_intensity_zscore', data=plot_data, palette='viridis')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Violin Plot of Max Pixel Intensity Z-Score by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Max Pixel Intensity Z-Score')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tifffile import imread\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame that contains 'total_reads', 'Fluro_image', and 'cell_condition' columns\n",
    "\n",
    "# Step 1: Calculate the 80th percentile of total_reads\n",
    "ncc_cutoff = 113014 + 72160\n",
    "\n",
    "# Step 2: Split the data into two groups based on the ncc_cutoff\n",
    "below_80th = merged_df[merged_df['total_reads'] <= ncc_cutoff]\n",
    "above_80th = merged_df[merged_df['total_reads'] > ncc_cutoff]\n",
    "\n",
    "# Step 3: Calculate max pixel intensity for each group\n",
    "def get_max_intensity(row):\n",
    "    image_file = os.path.join(\"/projects/steiflab/archive/data/imaging/A138856A/MicroscopeImages/S0000\", row['Fluro_image'])\n",
    "    image = imread(image_file)\n",
    "    return image.max()\n",
    "\n",
    "# Apply the function to calculate max intensity for each group\n",
    "below_80th['max_intensity'] = below_80th.apply(get_max_intensity, axis=1)\n",
    "above_80th['max_intensity'] = above_80th.apply(get_max_intensity, axis=1)\n",
    "\n",
    "# Combine the results into a single DataFrame for plotting\n",
    "plot_data = pd.concat([\n",
    "    below_80th[['max_intensity']].assign(group='Below ncc_cutoff'),\n",
    "    above_80th[['max_intensity']].assign(group='Above ncc_cutoff')\n",
    "])\n",
    "\n",
    "# Step 4: Create a boxplot to visualize the distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='group', y='max_intensity', data=plot_data, palette='viridis')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot of Max Pixel Intensity by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Max Pixel Intensity')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
